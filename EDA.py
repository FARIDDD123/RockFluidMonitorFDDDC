import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import plotly.express as px
from ydata_profiling import ProfileReport
import warnings
warnings.filterwarnings('ignore')

plt.style.use('ggplot')
pd.set_option('display.max_columns', 50)

def comprehensive_eda(file_path, output_dir="eda_results"):
    """ØªØ­Ù„ÛŒÙ„ Ø§Ú©ØªØ´Ø§ÙÛŒ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­ÙØ§Ø±ÛŒ"""
    # 1. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
    from pathlib import Path
    output_dir = "output"
    Path(output_dir).mkdir(exist_ok=True)
    Path(f"{output_dir}/plots").mkdir(exist_ok=True)
    
    # 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    df = pd.read_parquet(file_path)
    print(f"âœ… Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ {len(df)} Ø±Ú©ÙˆØ±Ø¯ Ùˆ {len(df.columns)} ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
    
    # 3. ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    print("\nğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
    print("ğŸ”¹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ:")
    print(df.info())
    
    # 4. ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ
    stats_report = df.describe(include='all').T
    stats_report['missing_%'] = (df.isnull().sum() / len(df)) * 100
    stats_report.to_csv(f"{output_dir}/statistical_report.csv")
    
    # 5. ØªØ­Ù„ÛŒÙ„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡
    plt.figure(figsize=(15, 8))
    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
    plt.title('Missing Values Analysis')
    plt.savefig(f"{output_dir}/plots/missing_values.png")
    plt.close()
    
    # 6. ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        try:
            plt.figure(figsize=(12, 6))
            sns.histplot(df[col], kde=True, bins=50)
            plt.title(f'Distribution of {col}')
            plt.savefig(f"{output_dir}/plots/dist_{col}.png")
            plt.close()
        except:
            continue
    
    # 7. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ outlierÙ‡Ø§
    def detect_outliers(df, columns, method='iqr'):
        outliers_report = {}
        for col in columns:
            if method == 'iqr':
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                outliers = df[(df[col] < (Q1 - 1.5*IQR)) | (df[col] > (Q3 + 1.5*IQR))]
            elif method == 'zscore':
                z_scores = stats.zscore(df[col].dropna())
                outliers = df[(np.abs(z_scores) > 3)]
            
            outliers_report[col] = {
                'count': len(outliers),
                'percentage': (len(outliers)/len(df))*100,
                'min_outlier': outliers[col].min() if len(outliers) > 0 else None,
                'max_outlier': outliers[col].max() if len(outliers) > 0 else None
            }
            
            # Ø±Ø³Ù… boxplot
            plt.figure(figsize=(8, 6))
            sns.boxplot(y=df[col])
            plt.title(f'Boxplot for {col}')
            plt.savefig(f"{output_dir}/plots/boxplot_{col}.png")
            plt.close()
        
        return pd.DataFrame(outliers_report).T
    
    outliers_iqr = detect_outliers(df, numeric_cols, 'iqr')
    outliers_zscore = detect_outliers(df, numeric_cols, 'zscore')
    outliers_iqr.to_csv(f"{output_dir}/outliers_iqr_report.csv")
    outliers_zscore.to_csv(f"{output_dir}/outliers_zscore_report.csv")
    
    # 8. ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
    plt.figure(figsize=(20, 15))
    corr = df[numeric_cols].corr()
    sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', center=0)
    plt.title('Correlation Matrix')
    plt.savefig(f"{output_dir}/plots/correlation_matrix.png")
    plt.close()
    
    # 9. ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    for col in categorical_cols:
        plt.figure(figsize=(12, 6))
        df[col].value_counts().plot(kind='bar')
        plt.title(f'Distribution of {col}')
        plt.savefig(f"{output_dir}/plots/cat_dist_{col}.png")
        plt.close()
        
        # ØªØ­Ù„ÛŒÙ„ Ø±Ø§Ø¨Ø·Ù‡ Ø¨Ø§ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù‡Ø¯Ù
        if 'Formation_Damage_Index' in df.columns:
            plt.figure(figsize=(12, 6))
            sns.boxplot(x=col, y='Formation_Damage_Index', data=df)
            plt.title(f'Formation Damage Index by {col}')
            plt.savefig(f"{output_dir}/plots/target_{col}.png")
            plt.close()
    
    # 10. ØªØ­Ù„ÛŒÙ„ Ù‡Ø¯Ùâ€ŒÙ…Ø­ÙˆØ±
    target_vars = ['Emulsion_Risk', 'Fluid_Loss_Risk', 'Formation_Damage_Index']
    for target in target_vars:
        if target in df.columns:
            # ØªØ­Ù„ÛŒÙ„ Ø±Ø§Ø¨Ø·Ù‡ Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
            top_corr = corr[target].sort_values(ascending=False)
            top_corr.to_csv(f"{output_dir}/top_correlations_{target}.csv")
            
            # ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹
            plt.figure(figsize=(12, 6))
            sns.histplot(df[target], kde=True, bins=50)
            plt.title(f'Distribution of {target}')
            plt.savefig(f"{output_dir}/plots/target_dist_{target}.png")
            plt.close()
    
    # 11. ØªØ­Ù„ÛŒÙ„ Ø²Ù…Ø§Ù†ÛŒ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ† Ø²Ù…Ø§Ù†ÛŒ)
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['hour'] = df['timestamp'].dt.hour
        df['day'] = df['timestamp'].dt.day
        df['month'] = df['timestamp'].dt.month
        
        plt.figure(figsize=(15, 8))
        df.groupby('day')['Formation_Damage_Index'].mean().plot()
        plt.title('Daily Average Formation Damage Index')
        plt.savefig(f"{output_dir}/plots/time_analysis.png")
        plt.close()
    
    # 12. ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ HTML
    print("\nğŸ“ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹...")
    profile = ProfileReport(df, title="Drilling Data EDA Report", explorative=True)
    profile.to_file(f"{output_dir}/drilling_eda_report.html")
    
    # 13. Ø®Ù„Ø§ØµÙ‡â€ŒÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    recommendations = generate_recommendations(df, output_dir)
    
    print(f"\nğŸ‰ ØªØ­Ù„ÛŒÙ„ Ø§Ú©ØªØ´Ø§ÙÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯! Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ù¾ÙˆØ´Ù‡ '{output_dir}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    return df.head(), recommendations

def generate_recommendations(df, output_dir):
    """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
    recs = []
    
    # ØªØ­Ù„ÛŒÙ„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡
    missing_cols = df.isnull().sum()[df.isnull().sum() > 0].index.tolist()
    if missing_cols:
        recs.append("ğŸš¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡: " + ", ".join(missing_cols))
        recs.append("âœ… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ Ø¨Ø§ Ù…ÛŒØ§Ù†Ù‡ (Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ) ÛŒØ§ Ù…Ø¯ (Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ)")
    
    # ØªØ­Ù„ÛŒÙ„ outlierÙ‡Ø§
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df[col].skew() > 3:
            recs.append(f"âš ï¸ Ø³ØªÙˆÙ† {col} Ø¯Ø§Ø±Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ø¨Ø³ÛŒØ§Ø± Ø§Ø±ÛŒØ¨ Ø§Ø³Øª (Skewness: {df[col].skew():.2f})")
            recs.append(f"âœ… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§Ø¹ØªØ¨Ø§Ø±ÛŒØ§Ø¨ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ¨Ø¯ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ú¯Ø§Ø±ÛŒØªÙ…ÛŒ")
    
    # ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
    corr = df[numeric_cols].corr().abs()
    high_corr = [(col1, col2, corr.loc[col1, col2]) 
                for col1 in corr.columns for col2 in corr.columns 
                if col1 < col2 and corr.loc[col1, col2] > 0.8]
    if high_corr:
        recs.append("ğŸ”— ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§ (>0.8):")
        for pair in high_corr:
            recs.append(f"   - {pair[0]} Ùˆ {pair[1]}: {pair[2]:.2f}")
        recs.append("âœ… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø¨Ø±Ø±Ø³ÛŒ multicollinearity Ùˆ Ø­Ø°Ù ÛŒÚ©ÛŒ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø¨Ø³ØªÙ‡")
    
    # ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù
    if 'Formation_Damage_Index' in df.columns:
        target_corr = corr['Formation_Damage_Index'].sort_values(ascending=False)
        top_features = target_corr.index[1:6].tolist()
        recs.append(f"ğŸ¯ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø± Ø¨Ø± Formation_Damage_Index: {', '.join(top_features)}")
    
    # Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    with open(f"{output_dir}/recommendations.txt", "w") as f:
        f.write("\n".join(recs))
    
    return recs

# Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
file_path = "synthetic_fdms_chunks/FDMS_well_WELL_1.parquet"
sample_data, recommendations = comprehensive_eda(file_path)

# Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
print("\nÙ†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
display(sample_data)

print("\nØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ:")
for rec in recommendations[:10]:  # Ù†Ù…Ø§ÛŒØ´ 10 ØªÙˆØµÛŒÙ‡ Ø§ÙˆÙ„
    print(f"- {rec}")
