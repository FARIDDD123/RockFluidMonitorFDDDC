# ğŸ“„ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø¯ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­ÙØ§Ø±ÛŒ

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø±Ø§ÛŒ **Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø­ÙØ§Ø±ÛŒ** Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ùˆ Ù…Ø±Ø§Ø­Ù„ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÙØ§ÛŒÙ„ `.parquet` Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:

- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
- Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ (NaN)
- Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
- Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ
- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ø¨Ø§ Z-Score Ùˆ IQR
- Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ú©â€ŒØ´Ø¯Ù‡ØŒ Ù¾Ø±Øªâ€ŒÙ‡Ø§ Ùˆ Ø¢Ù…Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ)

---

## ğŸ“ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§

```text
dataset/
â”œâ”€â”€ fdms_well_datasets/       # ÙˆØ±ÙˆØ¯ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ .parquet Ø®Ø§Ù… Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú†Ø§Ù‡
â”œâ”€â”€ processed/                # Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ú©â€ŒØ´Ø¯Ù‡
â”œâ”€â”€ outliers/                 # Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª
â”œâ”€â”€ means/                    # Ø¢Ù…Ø§Ø± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ùˆ Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ù‡Ø± Ú†Ø§Ù‡ (JSON)
```

---

## ğŸ”„ Ù…Ø±Ø§Ø­Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

### 1. Ø³Ø§Ø®Øª Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
```python
Path(PROCESSED_DIR).mkdir(parents=True, exist_ok=True)
Path(OUTLIER_DIR).mkdir(parents=True, exist_ok=True)
Path(MEAN_DIR).mkdir(parents=True, exist_ok=True)
```

### 2. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ùˆ Ø­Ø°Ù NaN
```python
df = pd.read_parquet(raw_path)
df = df.dropna()
```

### 3. Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
```python
original_means = df[numeric_cols].mean().to_dict()
original_stds = df[numeric_cols].std().to_dict()
```

### 4. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
```python
scaler = MinMaxScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
```

### 5. ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ
```python
df = pd.get_dummies(df, columns=categorical_cols)
```

### 6. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª

#### ğŸ”¹ Z-Score:
```python
z_scores = np.abs(stats.zscore(df[numeric_cols]))
outliers_z = (z_scores > 3).any(axis=1)
```

#### ğŸ”¹ IQR:
```python
Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1
outliers_iqr = ((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)
```

#### ğŸ”¹ ØªØ±Ú©ÛŒØ¨ Ù†Ù‡Ø§ÛŒÛŒ:
```python
outliers = outliers_z | outliers_iqr
```

### 7. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ…ÛŒØ²
```python
df_outliers.to_parquet(outliers_path, index=False)
df_clean = df[~outliers]
df_clean.to_parquet(processed_path, index=False)
```

### 8. Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ù‡ ÙØ±Ù…Øª JSON
```python
stats_to_save = {
    "WELL_ID": int(well_id),
    "mean": original_means,
    "std": original_stds
}
with open(mean_json_path, 'w') as f:
    json.dump(stats_to_save, f, indent=4)
```

---

## âœ… Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§

| Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡              | Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ                            |
|----------------------|----------------------------------------|
| Ø¯Ø§Ø¯Ù‡ Ù¾Ø§Ú©â€ŒØ´Ø¯Ù‡         | `dataset/processed/cleaned_<ID>.parquet` |
| Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Øª         | `dataset/outliers/outliers_<ID>.parquet` |
| Ø¢Ù…Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†ØŒ std) | `dataset/means/mean_<ID>.json`             |
